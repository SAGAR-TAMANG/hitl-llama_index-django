{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from llama_index.core import set_global_handler\n",
    "\n",
    "px.launch_app()\n",
    "set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from llama_index.core.workflow import (step, StartEvent, StopEvent, Workflow, Event, Context)\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker \n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from colorama import Fore, Style\n",
    "from typing import (Optional, List, Callable)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import prompts\n",
    "import os\n",
    "\n",
    "# Custom Events that runs custom functions\n",
    "\n",
    "class InitializeEvent(Event):\n",
    "\tpass\n",
    "\n",
    "class ConciergeEvent(Event):\n",
    "    request: Optional[str] = None\n",
    "    just_completed: Optional[str] = None\n",
    "    need_help: Optional[bool] = None\n",
    "\n",
    "class OrchestratorEvent(Event):\n",
    "\trequest: str\n",
    "\n",
    "class GraphGenerateEvent(Event):\n",
    "\trequest: str\n",
    "\n",
    "class DataFrameLookupEvent(Event):\n",
    "\trequest: str\n",
    "\n",
    "class MainWorkflow(Workflow):\n",
    "\t\"\"\"Main Workflow\n",
    "\n",
    "\tThe main workflow that runs the whole application's steps, calling all the Events from StartEvent -> StopEvent.\n",
    "\t\"\"\"\n",
    "\t@step(pass_context=True)\n",
    "\tasync def initialiation(self, ctx: Context, ev: InitializeEvent) -> ConciergeEvent:\n",
    "\t\tctx.data[\"user\"] = {\n",
    "\t\t\t\"username\": None,\n",
    "\t\t\t\"access_token\": None,\n",
    "\t\t\t\"session_token\": None,\n",
    "\t\t\t\"fb_access_key\": None,\n",
    "\t\t}\n",
    "\t\tctx.data[\"success\"] = None\n",
    "\t\tctx.data[\"redirecting\"] = None\n",
    "\t\tctx.data[\"overall_request\"] = None\n",
    "\t\tctx.data[\"llm\"] = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\t\treturn ConciergeEvent()\n",
    "  \n",
    "\t@step(pass_context=True)\n",
    "\tasync def concierge(self, ctx: Context, ev: ConciergeEvent | StartEvent) -> InitializeEvent | OrchestratorEvent | StopEvent:\n",
    "\t\t# initialize user if not already\n",
    "\t\t# if not ctx.data[\"user\"]:\n",
    "\t\tif (\"user\" not in ctx.data):\n",
    "\t\t\treturn InitializeEvent()\n",
    "\t\t\n",
    "\t\t# initialize concierge if not already\n",
    "\t\tif (\"concierge\" not in ctx.data):\n",
    "\t\t\tsystem_prompt = prompts.initialiation\n",
    "\t\t\t\n",
    "\t\t\tagent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "\t\t\t\ttools = [],\n",
    "\t\t\t\tllm = ctx.data[\"llm\"],\n",
    "\t\t\t\tallow_parallel_tool_calls = False,\n",
    "\t\t\t\tsystem_prompt = system_prompt,\n",
    "\t\t\t)\n",
    "\t\t\tctx.data[\"concierge\"] = agent_worker.as_agent()\n",
    "\n",
    "\t\tconcierge = ctx.data[\"concierge\"]\n",
    "\t\tif ctx.data[\"overall_request\"] is not None:\n",
    "\t\t\tprint(\"In Progress - 'overall_request':\", ctx.data[\"overall_request\"])\n",
    "\t\t\tlast_request = ctx.data[\"overall_request\"]\n",
    "\t\t\tctx.data[\"overall_request\"] = None\n",
    "\t\t\treturn OrchestratorEvent(request = last_request)\n",
    "\t\telif (ev.just_completed is not None):\n",
    "\t\t\tresponse = concierge.chat(f\"User Just Completed a Task: {ev.just_completed}\")\n",
    "\t\telif (ev.need_help):\n",
    "\t\t\tprint(\"The previous post needs help with\", ev.request)\n",
    "\t\t\treturn OrchestratorEvent(request = ev.request)\n",
    "\t\telif (ev.request):\n",
    "\t\t\tresponse = concierge.chat(ev.request)\n",
    "\t\telse:\n",
    "\t\t\t# first time experience\n",
    "\t\t\tresponse = concierge.chat(\"Hello!\")\n",
    "\t\t\n",
    "\t\tprint(\n",
    "\t\t\tFore.MAGENTA\n",
    "\t\t\t+ f\"SYSTEM >> {response}\"\n",
    "\t\t\t+ Style.RESET_ALL\n",
    "\t\t\t)\n",
    "\n",
    "\t\tuser_msg_str = input(\"USER >> \").strip()\n",
    "\t\treturn OrchestratorEvent(request = user_msg_str)\n",
    "\t\n",
    "\t@step(pass_context=True)\n",
    "\tasync def orchestrator(self, ctx: Context, ev: OrchestratorEvent) -> ConciergeEvent | GraphGenerateEvent | DataFrameLookupEvent:\n",
    "\t\t\n",
    "\t\tprint(f\"Orchestrator received a request: {ev.request}\")\n",
    "\n",
    "\t\t# tools are listed below as functions\n",
    "\t\tdef emit_dataframe_lookup() -> bool:\n",
    "\t\t\t\"\"\"Call this function if a dataframe needs to be accessed.\"\"\"\n",
    "\t\t\tprint(\"__emitted: dataframe lookup\")\n",
    "\t\t\tself.send_event(DataFrameLookupEvent(request=ev.request))\n",
    "\t\t\treturn True\n",
    "\t\t\n",
    "\t\tdef emit_graph_generator() -> bool:\n",
    "\t\t\t\"\"\"Call this function if a graph needs to be generated.\"\"\"\n",
    "\t\t\tprint(\"__emitted: graph lookup\")\n",
    "\t\t\tself.send_event(GraphGenerateEvent(request=ev.request))\n",
    "\t\t\treturn True\n",
    "\n",
    "\t\t# functions are then converted into tools\n",
    "\t\ttools = [\n",
    "\t\t\tFunctionTool.from_defaults(fn=emit_dataframe_lookup),\n",
    "\t\t\tFunctionTool.from_defaults(fn=emit_graph_generator),\n",
    "\t\t]\n",
    "\n",
    "\t\tsystem_prompt = prompts.orchestrator\n",
    "\n",
    "\t\tagent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "\t\t\t\ttools = tools,\n",
    "\t\t\t\tllm = ctx.data[\"llm\"],\n",
    "\t\t\t\tallow_parallel_tool_calls = False,\n",
    "\t\t\t\tsystem_prompt = system_prompt,\n",
    "\t\t)\n",
    "\n",
    "\t\tctx.data[\"orchestrator\"] = agent_worker.as_agent()\n",
    "\t\torchestrator = ctx.data[\"orchestrator\"]\n",
    "\t\tresponse = orchestrator.chat(ev.request)\n",
    "\n",
    "\t\tif str(response) == \"FAILED\":\n",
    "\t\t\tprint(\"Orchestrator agent failed to return any tools; try again\")\n",
    "\t\t\treturn ConciergeEvent(request = ev.request)\n",
    "\t\t\n",
    "\t###\n",
    "\n",
    "\t@step(pass_context=True)\n",
    "\tasync def get_dataframe(self, ctx: Context, ev: DataFrameLookupEvent) -> ConciergeEvent:\n",
    "\n",
    "\t\tprint(f\"Dateframe lookup received request: {ev.request}\")\n",
    "\n",
    "\t\tif (\"get_dataframe_agent\" not in ctx.data): \n",
    "\t\t\t# tools are listed below as functions\n",
    "\t\t\tdef get_campaign_df_data() -> str:\n",
    "\t\t\t\t\"\"\"Call this if the \"campaign\" dataframe is required\"\"\"\n",
    "\t\t\t\tprint(f\"Generating graph for \")\n",
    "\t\t\t\treturn \"Here's the generated Graph\"\n",
    "\n",
    "\t\t\tdef get_ad_account_df_data() -> str:\n",
    "\t\t\t\t\"\"\"Call this if the \"ad account\" dataframe is required\"\"\"\n",
    "\t\t\t\tprint(f\"Generating graph for \")\n",
    "\t\t\t\treturn \"Here is an ad account df\"\n",
    "\n",
    "\t\t\t# functions are then converted into tools\n",
    "\t\t\ttools = [\n",
    "\t\t\t\tFunctionTool.from_defaults(fn=get_campaign_df_data),\n",
    "\t\t\t\tFunctionTool.from_defaults(fn=get_ad_account_df_data),\n",
    "\t\t\t]\n",
    "\n",
    "\t\t\tsystem_prompt = \"\"\n",
    "\n",
    "\t\t\tctx.data[\"get_dataframe_agent\"] = ConciergeAgent(\n",
    "\t\t\t\tname=\"Get Dataframe Agent\",\n",
    "\t\t\t\tparent= Workflow,\n",
    "\t\t\t\ttools= tools,\n",
    "\t\t\t\tsystem_prompt= system_prompt ,\n",
    "\t\t\t\tcontext= ctx,\n",
    "\t\t\t\t# current_event= DataFrameLookupEvent,\n",
    "\t\t\t\ttrigger_event= DataFrameLookupEvent\n",
    "\t\t\t)\n",
    "\t\t\n",
    "\t\treturn ctx.data[\"get_dataframe_agent\"].handle_event(ev)\n",
    "\n",
    "\t\n",
    "\t@step(pass_context=True)\n",
    "\tasync def graph_generator(self, ctx: Context, ev: GraphGenerateEvent) -> OrchestratorEvent:\n",
    "\n",
    "\t\tprint(f\"Graph generator lookup received request: {ev.request}\")\n",
    "\n",
    "\t\tif (\"generate_graph_agent\" not in ctx.data): \n",
    "\t\t\t# tools are listed below as functions\n",
    "\t\t\tdef get_bargraph() -> str:\n",
    "\t\t\t\t\"\"\"Call this if user requests a bar graph is required.\"\"\"\n",
    "\t\t\t\tprint(f\"Generating graph for bar\")\n",
    "\t\t\t\treturn \"Here's the generated Graph\"\n",
    "\n",
    "\t\t\tdef anyy() -> str:\n",
    "\t\t\t\t\"\"\"Call this if any other graphs are required.\"\"\"\n",
    "\t\t\t\tprint(f\"Generating graph for any\")\n",
    "\t\t\t\treturn \"Here's the generated Graph\"\n",
    "\n",
    "\t\t\t# functions are then converted into tools\n",
    "\t\t\ttools = [\n",
    "\t\t\t\tFunctionTool.from_defaults(fn=get_bargraph),\n",
    "\t\t\t\tFunctionTool.from_defaults(fn=anyy),\n",
    "\t\t\t]\n",
    "\n",
    "\t\t\tsystem_prompt = prompts.graph_generator\n",
    "\n",
    "\t\t\tctx.data[\"generate_graph_agent\"] = ConciergeAgent(\n",
    "\t\t\t\tname=\"Generate Graph Agent\",\n",
    "\t\t\t\tparent= Workflow,\n",
    "\t\t\t\ttools= tools,\n",
    "\t\t\t\tsystem_prompt= system_prompt ,\n",
    "\t\t\t\tcontext= ctx,\n",
    "\t\t\t\t# current_event= DataFrameLookupEvent,\n",
    "\t\t\t\ttrigger_event= DataFrameLookupEvent\n",
    "\t\t\t)\n",
    "\t\t\n",
    "\t\treturn ctx.data[\"generate_graph_agent\"].handle_event(ev)\n",
    "\n",
    "\n",
    "# building up from Workflow to handle Events\n",
    "class ConciergeAgent():\n",
    "\tname: str\n",
    "\tparent: Workflow\n",
    "\ttools: list[FunctionTool]\n",
    "\tsystem_prompt: str\n",
    "\tcontext: Context\n",
    "\tcurrent_event: Event\n",
    "\ttrigger_event: Event\n",
    "\t\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\tname: str,\n",
    "\t\t\tparent: Workflow,\n",
    "\t\t\ttools: List[Callable],\n",
    "\t\t\tsystem_prompt: str,\n",
    "\t\t\tcontext: Context,\n",
    "\t\t\ttrigger_event: Event,\n",
    "\t\t\t):\n",
    "\t\tself.name = name\n",
    "\t\tself.parent = parent\n",
    "\t\tself.context = context\n",
    "\t\tself.system_prompt = system_prompt\n",
    "\t\tself.context.data[\"redirecting\"] = False\n",
    "\t\tself.trigger_event = trigger_event\n",
    "\n",
    "\t\t# tools that are needed for everyone\n",
    "\t\tdef done() -> None:\n",
    "\t\t\t\"\"\"When you complete a task, call this.\"\"\"\n",
    "\t\t\tprint(f\"{self.name} is commplete\")\n",
    "\t\t\tself.context.data[\"redirecting\"] = True\n",
    "\t\t\tparent.send_event(ConciergeEvent(just_completed=self.name))\n",
    "\n",
    "\t\t# tools that are needed for everyone\n",
    "\t\tdef need_help() -> None:\n",
    "\t\t\t\"\"\"If the user asks you do something, call this.\"\"\"\n",
    "\t\t\tprint(f\"{self.name} is commplete\")\n",
    "\t\t\tself.context.data[\"redirecting\"] = True\n",
    "\t\t\tparent.send_event(ConciergeEvent(request = self.current_event.request, need_help=True))\n",
    "\n",
    "\t\tself.tools = [\n",
    "\t\t\tFunctionTool.from_defaults(fn=done),\n",
    "\t\t\tFunctionTool.from_defaults(fn=need_help),\n",
    "\t\t]\n",
    "\t\t\n",
    "\t\t# adding the Event's tools to the default tools\n",
    "\t\tfor t in tools:\n",
    "\t\t\tself.tools.append(FunctionTool.from_defaults(fn=t))\n",
    "\t\t\n",
    "\t\tagent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "\t\t\ttools = self.tools,\n",
    "\t\t\tllm = self.context.data[\"llm\"],\n",
    "\t\t\tallow_parallel_tool_calls = False,\n",
    "\t\t\tsystem_prompt = self.system_prompt,\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.agent = agent_worker.as_agent()\n",
    "\t\n",
    "\tdef handle_event(self, ev: Event):\n",
    "\t\tself.current_event = ev\n",
    "\n",
    "\t\tresponse = str(self.agent.chat(ev.request))\n",
    "\t\tprint(\n",
    "\t\t\tFore.MAGENTA\n",
    "\t\t\t+ \"SYSTEM >> {response}\"\n",
    "\t\t\t+ Style.RESET_ALL\n",
    "\t\t\t)\n",
    "\n",
    "\t\t# if they're sending us elsewhere, we're done here\n",
    "\t\tif self.context.data[\"redirecting\"]:\n",
    "\t\t\tself.context.data[\"redirecting\"] = False\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\t# otherwise, get some user input & then loop\n",
    "\t\tuser_msg_str = input(\"> \").strip()\n",
    "\t\treturn self.trigger_event(request=user_msg_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step concierge\n",
      "Step concierge produced event InitializeEvent\n",
      "Running step initialiation\n",
      "Step initialiation produced event ConciergeEvent\n",
      "Running step concierge\n",
      "\u001b[35mSYSTEM >> Hello! How can I assist you today?\u001b[0m\n",
      "Step concierge produced event OrchestratorEvent\n",
      "Running step orchestrator\n",
      "Orchestrator received a request: generate a graph for my campaigns\n",
      "__emitted: graph lookup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py:372: UserWarning: Use a Context instance to send events from a step. Make sure your step method or function takes a parameter of type Context like `ctx: Context` and replace `self.send_event(...)` with `ctx.send_event(...)` in your code.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step orchestrator produced no event\n",
      "Running step graph_generator\n",
      "Graph generator lookup received request: generate a graph for my campaigns\n"
     ]
    },
    {
     "ename": "WorkflowRuntimeError",
     "evalue": "Error in step 'graph_generator': 'FunctionTool' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py:247\u001b[0m, in \u001b[0;36mWorkflow._start.<locals>._task\u001b[1;34m(name, queue, step, config)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     new_ev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m instrumented_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# exit the retrying loop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:367\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 367\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[51], line 208\u001b[0m, in \u001b[0;36mMainWorkflow.graph_generator\u001b[1;34m(self, ctx, ev)\u001b[0m\n\u001b[0;32m    206\u001b[0m \tsystem_prompt \u001b[38;5;241m=\u001b[39m prompts\u001b[38;5;241m.\u001b[39mgraph_generator\n\u001b[1;32m--> 208\u001b[0m \tctx\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate_graph_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mConciergeAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate Graph Agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mWorkflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# current_event= DataFrameLookupEvent,\u001b[39;49;00m\n\u001b[0;32m    215\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mtrigger_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDataFrameLookupEvent\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate_graph_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mhandle_event(ev)\n",
      "Cell \u001b[1;32mIn[51], line 268\u001b[0m, in \u001b[0;36mConciergeAgent.__init__\u001b[1;34m(self, name, parent, tools, system_prompt, context, trigger_event)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[1;32m--> 268\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mappend(\u001b[43mFunctionTool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    270\u001b[0m agent_worker \u001b[38;5;241m=\u001b[39m FunctionCallingAgentWorker\u001b[38;5;241m.\u001b[39mfrom_tools(\n\u001b[0;32m    271\u001b[0m \ttools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools,\n\u001b[0;32m    272\u001b[0m \tllm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    273\u001b[0m \tallow_parallel_tool_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m \tsystem_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_prompt,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\llama_index\\core\\tools\\function_tool.py:80\u001b[0m, in \u001b[0;36mFunctionTool.from_defaults\u001b[1;34m(cls, fn, name, description, return_direct, fn_schema, async_fn, tool_metadata)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m fn_to_parse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfn or async_fn must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 80\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfn_to_parse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\n\u001b[0;32m     81\u001b[0m docstring \u001b[38;5;241m=\u001b[39m fn_to_parse\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FunctionTool' object has no attribute '__name__'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mWorkflowRuntimeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m wf \u001b[38;5;241m=\u001b[39m MainWorkflow(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# draw_all_possible_flows(wf, filename=\"workflow.html\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m wf\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py:440\u001b[0m, in \u001b[0;36mWorkflow.run.<locals>._run_workflow\u001b[1;34m()\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_raised:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_raised\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m we_done:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[0;32m    444\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n",
      "File \u001b[1;32mc:\\Users\\TAMANG\\Documents\\GitHub\\leapx\\sagar-chat-with-backend\\venv\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py:254\u001b[0m, in \u001b[0;36mWorkflow._start.<locals>._task\u001b[1;34m(name, queue, step, config)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mretry_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WorkflowRuntimeError(\n\u001b[0;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in step \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     delay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mretry_policy\u001b[38;5;241m.\u001b[39mnext(\n\u001b[0;32m    259\u001b[0m         retry_start_at \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mtime(), attempts, e\n\u001b[0;32m    260\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m delay \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;66;03m# We're done retrying\u001b[39;00m\n",
      "\u001b[1;31mWorkflowRuntimeError\u001b[0m: Error in step 'graph_generator': 'FunctionTool' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "wf = MainWorkflow(timeout=10, verbose=True)\n",
    "# draw_all_possible_flows(wf, filename=\"workflow.html\")\n",
    "result = await wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
